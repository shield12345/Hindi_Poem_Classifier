# -*- coding: utf-8 -*-
"""Pre-Processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SBBgvl9G-flz1aT6W9So01pkWzeCC7eX
"""

!pip install inltk

import csv
import pickle

from inltk.inltk import setup

# setup("hi")
#This will give runtime error; check if it displays "done", if not run again after some time.

"""# Pre-processing"""

from inltk.inltk import tokenize

poems_data_path = './poems_data_merged.csv'
# 3 files for stopwords, decide later which one gives better results
stop_words_path = './stopwords1.txt'

poems_data = open(poems_data_path,'r')
stop_words_file = open(stop_words_path,'r')

reader = csv.reader(poems_data, delimiter=',')

stop_words = []
for stop_word in stop_words_file:
	stop_words.append(stop_word)

line_count = 0

all_data = []

for col in reader:
	if (line_count == 0):
		pass
	else:
		tokenized_poem = tokenize(col[4],'hi')
		filtered_poem = [word for word in tokenized_poem if not word in stop_words] 
		all_data.append([col[0],col[1],col[2],col[3],filtered_poem])
		print(str(line_count) + "       " + col[2])
	line_count += 1

with open('processed_data.txt', 'wb') as processed_data:
   pickle.dump(all_data, processed_data)